services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: ${PG_DB}
      POSTGRES_USER: ${PG_USER}
      POSTGRES_PASSWORD: ${PG_PASS}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${PG_USER} -d ${PG_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7
    command: ["redis-server", "--save", "", "--appendonly", "no",
              "--maxmemory", "${REDIS_MAXMEMORY}",
              "--maxmemory-policy", "${REDIS_POLICY}"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # --- SERVICIOS KAFKA ---
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ['CMD', 'bash', '-c', "echo 'ruok' | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.3.2
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_INTERNAL://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    ports:
      - "29092:29092"
    healthcheck:
      test: ['CMD', 'bash', '-c', 'kafka-topics --bootstrap-server kafka:9092 --list']
      interval: 15s
      timeout: 10s
      retries: 5

  kafka-init:
    image: confluentinc/cp-kafka:7.3.2
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./create_topics.sh:/tmp/create_topics.sh
    command: bash -c "/tmp/create_topics.sh && echo 'Tópicos creados, durmiendo...' && sleep infinity"

  # --- SERVICIOS APLICACIÓN ---
  storage-api:
    build: ./services/storage-api
    env_file: [.env]
    # --- MODIFICACIÓN T2: Añadir variables de entorno ---
    environment:
      PYTHONUNBUFFERED: "1"
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC_VALIDADOS: resultados_validados
      KAFKA_CONSUMER_GROUP_STORAGE: storage_consumer_group
      # Pasa el RUN_ID para que el consumidor sepa dónde guardar los resultados
      RUN_ID: ${RUN_ID:-dev_t2}
    # --- FIN MODIFICACIÓN ---
    depends_on:
      postgres:
        condition: service_healthy
      kafka: 
        condition: service_healthy
    ports:
      - "8001:8001"
    volumes:
      - ./data:/data:ro
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://localhost:8001/health', timeout=3).status==200 else 1)\""]
      interval: 10s
      timeout: 5s
      retries: 5

  cache-service:
    build: ./services/cache-service
    env_file: [.env]
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "8002:8002"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://localhost:8002/health', timeout=3).status==200 else 1)\""]
      interval: 10s
      timeout: 5s
      retries: 5

  responder-llm:
    build: ./services/responder-llm
    env_file: [.env]
    environment:
      LLM_MODE: GEMINI
      LLM_LANG: en
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      GEMINI_MODEL: gemini-2.5-flash
      GEMINI_API_VERSION: v1beta
    depends_on:
      {} 
    ports:
      - "8003:8003"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://localhost:8003/health', timeout=3).status==200 else 1)\""]
      interval: 10s
      timeout: 5s
      retries: 5

  scorer:
    build: ./services/scorer
    env_file: [.env]
    depends_on:
      {} 
    ports:
      - "8004:8004"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://localhost:8004/health', timeout=3).status==200 else 1)\""]
      interval: 10s
      timeout: 5s
      retries: 5

  # --- WORKERS KAFKA ---
  llm_worker:
    build: ./services/llm_worker
    env_file: [.env]
    environment:
      PYTHONUNBUFFERED: "1"
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC_PREGUNTAS: preguntas_nuevas
      KAFKA_TOPIC_RESP_OK: respuestas_llm_ok
      KAFKA_TOPIC_RESP_REINTENTAR: respuestas_llm_fallidas_reintentar
      URL_RESPONDER_LLM: http://responder-llm:8003/answer
      MAX_RETRIES: ${MAX_RETRIES:-3}
    depends_on:
      kafka:
        condition: service_healthy
      responder-llm:
        condition: service_healthy

  retry_worker:
    build: ./services/retry_worker
    env_file: [.env]
    environment:
      PYTHONUNBUFFERED: "1"
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC_RESP_REINTENTAR: respuestas_llm_fallidas_reintentar
      KAFKA_TOPIC_PREGUNTAS: preguntas_nuevas
      RETRY_BASE_DELAY_S: ${RETRY_BASE_DELAY_S:-5}
      RETRY_MAX_DELAY_S: ${RETRY_MAX_DELAY_S:-60}
    depends_on:
      kafka:
        condition: service_healthy

  # --- SERVICIOS FLINK ---
  jobmanager:
    image: flink:1.17 
    ports:
      - "8081:8081" 
    command: jobmanager 
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - FLINK_PROPERTIES=jobmanager.memory.process.size: 1024m
    depends_on:
      kafka: 
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/overview || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5

  taskmanager:
    image: flink:1.17
    command: taskmanager 
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
      - |
        FLINK_PROPERTIES=taskmanager.memory.process.size: 1024m
        taskmanager.numberOfTaskSlots: 1
    depends_on:
      jobmanager: 
        condition: service_healthy
      kafka: 
        condition: service_healthy

  # --- SUBMITTER JOB FLINK ---
  flink-job-submitter:
    build: ./services/flink_job
    environment:
      - PYTHONUNBUFFERED=1
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC_RESP_OK=respuestas_llm_ok
      - KAFKA_TOPIC_VALIDADOS=resultados_validados
      - KAFKA_TOPIC_PREGUNTAS=preguntas_nuevas
      - URL_SCORER=http://scorer:8004/score
      - SCORE_THRESHOLD=${SCORE_THRESHOLD:-0.1}
      - MAX_FLINK_RETRIES=${MAX_FLINK_RETRIES:-1}
    depends_on:
      jobmanager: 
        condition: service_healthy
      taskmanager: 
        condition: service_healthy
      scorer: 
         condition: service_healthy
    command: >
      bash -c "
        echo 'Esperando a que Flink se estabilice...' &&
        sleep 15 &&
        echo 'Enviando el job PyFlink...' &&
        flink run \
          --python /opt/flink/job/job.py \
          --jobmanager jobmanager:8081
      "

  # --- GENERADOR DE TRÁFICO (MODIFICADO T2) ---
  traffic-gen:
    build: ./services/traffic-gen
    env_file: [.env]
    environment:
      PYTHONUNBUFFERED: "1"
      TOTAL_REQUESTS: ${TOTAL_REQUESTS:-0}
      TRAFFIC_DIST: ${TRAFFIC_DIST:-poisson}
      BASE_RATE_RPS: ${BASE_RATE_RPS:-5} 
      DURATION_SECONDS: ${DURATION_SECONDS:-120}
      URL_STORAGE: http://storage-api:8001
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    depends_on:
      storage-api:
        condition: service_healthy
      kafka-init: # Espera a que los tópicos estén creados
        condition: service_started 

volumes:
  pgdata:

