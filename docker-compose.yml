
services:
  # Este servicio corre Postgres 16 para persistencia de resultados del flujo validado.
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: ${PG_DB}
      POSTGRES_USER: ${PG_USER}
      POSTGRES_PASSWORD: ${PG_PASS}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${PG_USER} -d ${PG_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Este servicio expone Redis 7 como caché/kv auxiliar para el proyecto.
  redis:
    image: redis:7
    command: ["redis-server", "--save", "", "--appendonly", "no",
              "--maxmemory", "${REDIS_MAXMEMORY}",
              "--maxmemory-policy", "${REDIS_POLICY}"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Este servicio provee ZooKeeper requerido por cp-kafka 7.3.x.
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ['CMD', 'bash', '-c', "echo ruok | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Este servicio levanta Kafka con listeners interno (9092) y externo (29092).
  kafka:
    image: confluentinc/cp-kafka:7.3.2
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # Define listeners y su mapeo de protocolo (interno y externo).
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_INTERNAL://localhost:29092
      # Ajustes single-node para fines de laboratorio.
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    ports:
      - "29092:29092"
    healthcheck:
      test: ['CMD', 'bash', '-c', 'kafka-topics --bootstrap-server kafka:9092 --list']
      interval: 15s
      timeout: 10s
      retries: 5

  # Este servicio inicializa los tópicos del proyecto y queda durmiendo.
  kafka-init:
    image: confluentinc/cp-kafka:7.3.2
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./create_topics.sh:/tmp/create_topics.sh
    command: bash -c "/tmp/create_topics.sh && echo 'Tópicos creados, durmiendo...' && sleep infinity"

  # Este servicio expone la API de almacenamiento y corre el consumidor de Kafka en background.
  storage-api:
    build:
      context: ./services/storage-api
      # Si el Dockerfile no se llama "Dockerfile" (por ejemplo "dockerfile"), se declara aquí:
      # dockerfile: dockerfile
    env_file: [.env]
    environment:
      PYTHONUNBUFFERED: "1"
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC_VALIDADOS: resultados_validados
      KAFKA_CONSUMER_GROUP_STORAGE: storage_consumer_group
      RUN_ID: ${RUN_ID:-dev_t2}
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
    ports:
      - "8001:8001"
    volumes:
      - ./data:/data:ro
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://localhost:8001/health', timeout=3).status==200 else 1)\""]
      interval: 10s
      timeout: 5s
      retries: 5

  # Este servicio expone un microservicio de caché HTTP apoyado en Redis.
  cache-service:
    build:
      context: ./services/cache-service
    env_file: [.env]
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "8002:8002"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://localhost:8002/health', timeout=3).status==200 else 1)\""]
      interval: 10s
      timeout: 5s
      retries: 5

  # Este servicio ofrece la API del LLM (stub o GEMINI) para que el worker consulte respuestas.
  responder-llm:
    build:
      context: ./services/responder-llm
      # Si el Dockerfile se llama "dockerfile" (minúsculas), se habilita la línea siguiente.
      # dockerfile: dockerfile
    env_file: [.env]
    environment:
      LLM_MODE: GEMINI
      LLM_LANG: en
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      GEMINI_MODEL: gemini-2.5-flash
      GEMINI_API_VERSION: v1beta
    ports:
      - "8003:8003"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://localhost:8003/health', timeout=3).status==200 else 1)\""]
      interval: 10s
      timeout: 5s
      retries: 5

  # Este servicio calcula el score de las respuestas y expone /score para Flink.
  scorer:
    build:
      context: ./services/scorer
    env_file: [.env]
    ports:
      - "8004:8004"
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request,sys; sys.exit(0 if urllib.request.urlopen('http://localhost:8004/health', timeout=3).status==200 else 1)\""]
      interval: 10s
      timeout: 5s
      retries: 5

  # Este servicio consume preguntas, llama al LLM y publica en respuestas_ok o reintentar.
  llm_worker:
    build:
      context: ./services/llm_worker
    env_file: [.env]
    environment:
      PYTHONUNBUFFERED: "1"
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC_PREGUNTAS: preguntas_nuevas
      KAFKA_TOPIC_RESP_OK: respuestas_llm_ok
      KAFKA_TOPIC_RESP_REINTENTAR: respuestas_llm_fallidas_reintentar
      URL_RESPONDER_LLM: http://responder-llm:8003/answer
      MAX_RETRIES: ${MAX_RETRIES:-3}
    depends_on:
      kafka:
        condition: service_healthy
      responder-llm:
        condition: service_healthy
      kafka-init:
        condition: service_started
  
  # Este servicio reinyecta mensajes según política de backoff y límites.
  retry_worker:
    build:
      context: ./services/retry_worker
    env_file: [.env]
    environment:
      PYTHONUNBUFFERED: "1"
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC_RESP_REINTENTAR: respuestas_llm_fallidas_reintentar
      KAFKA_TOPIC_PREGUNTAS: preguntas_nuevas
      RETRY_BASE_DELAY_S: ${RETRY_BASE_DELAY_S:-5}
      RETRY_MAX_DELAY_S: ${RETRY_MAX_DELAY_S:-60}
    depends_on:
      kafka:
        condition: service_healthy
      kafka-init:
        condition: service_started

  # Este servicio levanta el JobManager de Flink (1.17 con PyFlink).
  jobmanager:
    build: ./docker/flink-py
    command: jobmanager  
    image: apache/flink:1.17.1-python3.11
    ports:
      - "8081:8081"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 3
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./jars/flink-sql-connector-kafka-1.17.1.jar:/opt/flink/opt/flink-sql-connector-kafka-1.17.1.jar:ro
    healthcheck:
      test: ["CMD-SHELL","curl -f http://localhost:8081/overview || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5

  # Este servicio levanta el TaskManager de Flink.
  taskmanager:
    build: ./docker/flink-py
    command: taskmanager  
    image: apache/flink:1.17.1-python3.11
    environment:
       - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 1
        taskmanager.memory.process.size: 1024m
    depends_on:
      jobmanager:
        condition: service_healthy
      kafka:
        condition: service_healthy  # <-- corregido el typo (antes decía service_health)
    volumes:
      - ./jars/flink-sql-connector-kafka-1.17.1.jar:/opt/flink/opt/flink-sql-connector-kafka-1.17.1.jar:ro
  # Este servicio instala deps del job PyFlink, espera, y hace el submit al JobManager.
    # Este servicio instala dependencias del job PyFlink y hace el submit al JobManager.
  flink-job-submitter:
    build: ./docker/flink-py
    depends_on:
      jobmanager:
        condition: service_healthy
      taskmanager:
        condition: service_started
      scorer:
        condition: service_healthy
    volumes:
      - ./jars/flink-sql-connector-kafka-1.17.1.jar:/opt/flink/opt/flink-sql-connector-kafka-1.17.1.jar:ro
      - ./services/flink_job:/job:ro
    environment:
      PYTHONUNBUFFERED: "1"
    command:
      - /bin/bash
      - -lc
      - >
        echo "[submitter] Copiando submit.sh a /tmp y normalizando CRLF…";
        awk '{ sub(/\r$/,""); print }' /job/submit.sh > /tmp/submit.sh;
        chmod +x /tmp/submit.sh;
        /bin/bash /tmp/submit.sh
  # Este servicio genera tráfico (Poisson/bursty) hacia preguntas_nuevas.
  traffic-gen:
    build:
      context: ./services/traffic-gen
    depends_on:
      kafka:
        condition: service_healthy
      storage-api:
        condition: service_healthy
    environment:
      RUN_ID: "t2-smoke"
      BASE_RATE_RPS: "5"
      DURATION_SECONDS: "30"
      TOTAL_REQUESTS: "0"
      TRAFFIC_DIST: "poisson"
      MAX_CONCURRENCY: "64"
      HTTP_TIMEOUT: "5"
      KAFKA_BOOTSTRAP_SERVERS: "kafka:9092"
      KAFKA_TOPIC_PREGUNTAS: "preguntas_nuevas"
      URL_STORAGE: "http://storage-api:8001"
    restart: "no"

volumes:
  pgdata: